\documentclass[preprint, twocolumn]{article}
\usepackage{mathptmx}
\usepackage{url,latexsym,amsmath,amsthm,xspace,rotating,multirow,multicol,xspace,amssymb,paralist}
\usepackage{euscript}
\usepackage{fancybox,xcolor}
\usepackage{longtable}
\usepackage{paralist}
\usepackage[normalem]{ulem}
\usepackage[pdftex]{hyperref}

\usepackage{url}
\usepackage{latexsym}

\usepackage{times}
\usepackage{amsmath}
\usepackage{amsthm}
\usepackage{amssymb}
\usepackage{graphicx}
\usepackage{xspace}
\usepackage{tabularx}
\usepackage{multicol}
\usepackage{multirow}
%\usepackage{hyperref}
\usepackage{url}
%\usepackage{natbib}
\usepackage{wrapfig}
\usepackage{comment}
\usepackage{listings}
\usepackage{color}
\usepackage[utf8]{inputenc}
\usepackage{fancyvrb}
\usepackage{booktabs}
\usepackage{color}
\usepackage[normalem]{ulem}

\newcommand{\obs}{\text{obs}}
\newcommand{\mis}{\text{mis}}

\newcommand{\qt}[1]{\left<#1\right>}
\newcommand{\ql}[1]{\left[#1\right]}
\newcommand{\hess}{\mathbf{H}}
\newcommand{\jacob}{\mathbf{J}}
\newcommand{\hl}{HL}
\newcommand{\cost}{\mathcal{L}}
\newcommand{\lout}{\mathbf{r}}
\newcommand{\louti}{r}
\newcommand{\outi}{y}
\newcommand{\out}{\mathbf{y}}
\newcommand{\gauss}{\mathbf{G_N}}
\newcommand{\eye}{\mathbf{I}}
\newcommand{\softmax}{\phi}
\newcommand{\targ}{\mathbf{t}}
\newcommand{\metric}{\mathbf{G}}
\newcommand{\sample}{\mathbf{z}}
\newcommand{\f}{\text{f}}
%\newcommand{\log}{\text{log}}

\newcommand{\bmx}[0]{\begin{bmatrix}}
\newcommand{\emx}[0]{\end{bmatrix}}
\newcommand{\qexp}[1]{\left<#1\right>}
\newcommand{\vect}[1]{\mathbf{#1}}
\newcommand{\vects}[1]{\boldsymbol{#1}}
\newcommand{\matr}[1]{\mathbf{#1}}
\newcommand{\var}[0]{\operatorname{Var}}
\newcommand{\std}[0]{\operatorname{std}}
\newcommand{\cov}[0]{\operatorname{Cov}}
\newcommand{\diag}[0]{\operatorname{diag}}
\newcommand{\matrs}[1]{\boldsymbol{#1}}
\newcommand{\va}[0]{\vect{a}}
\newcommand{\vb}[0]{\vect{b}}
\newcommand{\vc}[0]{\vect{c}}
\newcommand{\ve}[0]{\vect{e}}

\newcommand{\vh}[0]{\vect{h}}
\newcommand{\vv}[0]{\vect{v}}
\newcommand{\vx}[0]{\vect{x}}
\newcommand{\vz}[0]{\vect{z}}
\newcommand{\vw}[0]{\vect{w}}
\newcommand{\vs}[0]{\vect{s}}
\newcommand{\vf}[0]{\vect{f}}
\newcommand{\vi}[0]{\vect{i}}
\newcommand{\vo}[0]{\vect{o}}
\newcommand{\vy}[0]{\vect{y}}
\newcommand{\vg}[0]{\vect{g}}
\newcommand{\vm}[0]{\vect{m}}
\newcommand{\vu}[0]{\vect{u}}
\newcommand{\vL}[0]{\vect{L}}
\newcommand{\vr}[0]{\vect{r}}
\newcommand{\vone}[0]{\vect{1}}
\newcommand{\mW}[0]{\matr{W}}

\newcommand{\mE}[0]{\matr{E}}
\newcommand{\mG}[0]{\matr{G}}
\newcommand{\mX}[0]{\matr{X}}
\newcommand{\mY}[0]{\matr{Y}}
\newcommand{\mQ}[0]{\matr{Q}}
\newcommand{\mU}[0]{\matr{U}}
\newcommand{\mF}[0]{\matr{F}}
\newcommand{\mV}[0]{\matr{V}}
\newcommand{\mA}{\matr{A}}
\newcommand{\mC}{\matr{C}}
\newcommand{\mD}{\matr{D}}
\newcommand{\mS}{\matr{S}}
\newcommand{\mI}{\matr{I}}
\newcommand{\td}[0]{\text{d}}
\newcommand{\TT}[0]{\vects{\theta}}
\newcommand{\PP}[0]{\vects{\phi}}
\newcommand{\vsig}[0]{\vects{\sigma}}
\newcommand{\valpha}[0]{\vects{\alpha}}
\newcommand{\vmu}[0]{\vects{\mu}}
\newcommand{\vzero}[0]{\vect{0}}
\newcommand{\tf}[0]{\text{m}}
\newcommand{\tdf}[0]{\text{dm}}
\newcommand{\grad}[0]{\nabla}
\newcommand{\alert}[1]{\textcolor{red}{#1}}
\newcommand{\N}[0]{\mathcal{N}}
\newcommand{\LL}[0]{\mathcal{L}}
\newcommand{\HH}[0]{\mathcal{H}}
\newcommand{\RR}[0]{\mathbb{R}}
\newcommand{\MM}[0]{\mathcal{M}}
\newcommand{\OO}[0]{\mathbb{O}}
\newcommand{\NN}[0]{\mathcal{N}}
\newcommand{\II}[0]{\mathbb{I}}
\newcommand{\Scal}[0]{\mathcal{S}}
\newcommand{\sigmoid}{\sigma}
\newcommand{\E}[0]{\mathbb{E}}
\newcommand{\enabla}[0]{\ensuremath{%
    \overset{\raisebox{-0.3ex}[0.5ex][0ex]{%
    \ensuremath{\scriptscriptstyle e}}}{\nabla}}}
\newcommand{\enhnabla}[0]{\nabla_{\hspace{-0.5mm}e}\,}


\newcommand{\todo}[1]{{\Large\textcolor{red}{#1}}}
\newcommand{\done}[1]{{\Large\textcolor{green}{#1}}}
\newcommand{\dd}[1]{\ensuremath{\mbox{d}#1}}

\DeclareMathOperator*{\argmax}{\arg \max}
\DeclareMathOperator*{\argmin}{\arg \min}
\newcommand{\newln}{\\&\quad\quad{}}

\newcommand{\KL}{\text{KL}}
\newcommand{\data}{\text{data}}
\newcommand{\rect}{\text{rect}}
\newcommand{\train}{\text{train}}
\newcommand{\val}{\text{val}}
\newcommand{\test}{\text{test}}
\newcommand{\Ax}{\mathcal{A}_x}
\newcommand{\Ay}{\mathcal{A}_y}
\newcommand{\ola}{\overleftarrow}
\newcommand{\ora}{\overrightarrow}
\newcommand{\ov}{\overline}
\newcommand{\ts}{\rule{0pt}{2.6ex}}       % Top strut
\newcommand{\ms}{\rule{0pt}{0ex}}         % Middle strut
\newcommand{\bs}{\rule[-1.2ex]{0pt}{0pt}} % Bottom strut
\newcommand{\specialcell}[2][c]{%
  \begin{tabular}[#1]{@{}c@{}}#2\end{tabular}}


%\usepackage{bibentry}
%\nobibliography*

\begin{document}
\title{Gradient Backpropagation for Approximate Inference in Directed Belief Networks}
\author{Hjelm R. D., Jojic, N., Cho, K., Chung, J., Salakhutdinov, R., and Calhoun, V.}

\twocolumn[
  \begin{@twocolumnfalse}
    \maketitle
    \begin{abstract}
Deep directed graphical models, while representing a potentially powerful class of generative representations, are challenging to train due to difficult inference. Recent advances in variational inference, notably in variational autoencoders, have advanced well beyond traditional variational inference and MCMC methods. While these techniques offer higher flexibility as well as simpler and faster inference, they are still limited by the choice of the approximate posterior. Recently there has been interest in improving the approximate posterior through flexible priors and more involved inference procedures. We show that when the lower bound can be approximated as a deterministic function of the variational parameters, we can use standard gradient descent with back-propagation to improve the posterior and achieve a tighter lower bound. While our most notable results are with continuous latent variables, we show this can apply to binary latent variables as well with some success.
\end{abstract}
  \end{@twocolumnfalse}
  ]

\pagenumbering{arabic}

\section{Introduction}
Deep generative models offer the capacity for rich representations of complex data while (something about AI, reasoning, explaining away etc Neb?). Deep directed graphical models in particular have some advantage over their undirected cousins as they do not suffer from learning and evaluation issues arising from an intractable partition function. Despite their representational power, directed graphical models can be difficult to train, as the true posterior is typically intractable when the conditional has a complex or flexible parameterization, such as those modeled by a deep feed forward network with many layers of nonlinearities.

Recently, variational inference methods such as wake-sleep \cite{hinton1995wake, bornschein2014reweighted}, variational autoencoders (VAE) \cite{kingma2013auto}, and neural variational inference and learning (NVIL) \cite{mnih2014neural} have supplanted traditional MCMC and traditional variational methods such as mean field coordinate ascent inference due to flexible and fast inference. This is accomplished by introducing a complex and flexible feed forward network as a parametric function for the approximate posterior. As opposed to traditional methods, these provide a fast and effective means of performing inference and learning which scale very well to large datasets.

While advancements have been significant, these methods are still limited by the choice of approximate posterior: the approximate nature of the posterior translates to a looseness in the lower bound. Some recent work as begun to address limitations in the posterior by either relaxing the factorial condition \cite{burda2015importance} on the approximate posterior or through the introduction of auxiliary networks. Alternatively, there is work focusing on improving the inference procedure itself, such as by applying gradient descent to variational inference \cite{hoffman2013stochastic}. Other work on MCMC variational inference improves the approximate posterior through iterative MCMC transitions \cite{salimans2014markov}. We combine approaches of variational inference and gradient descent by augmenting variational inference starting at a parametric function defined by a deep feedforward network, using a gradient descent algorithm to improve inference. This way, we can sacrifice some computational efficiency in favor of a MCMC-like iterative procedure in order to improve the variational lower bound.

\section{Gradient Backprop Variational Inference}
Wake-sleep, VAE, and NVIL all optimize model parameters by minimizing the variational lower bound of the log likelihood:
\begin{align}
    \label{eq:approx_logp}
    \log p(x) =& \log \sum_{h} p(x, h) \nonumber \\
    =& \log \sum_h \tilde{q}(h|x) \frac{p(x, h)}{\tilde{q}(h|x)} \nonumber \\
    \geq& \sum_h \tilde{q}(h|x) \log \frac{p(x, h)}{\tilde{q}(h|x)} \nonumber \\
    =& \sum_h \tilde{q}(h|x) \log p(x,h) + \HH(\tilde{q}) \nonumber \\
    \approx& \frac{1}{N} \sum_{h^n} \log p(x, h^n) - \log
    \tilde{q}(h^n),
\end{align}
by introducing an approximate posterior $\tilde{q}_z$ with variational parameters $z$, where $\HH(\tilde{q})$ is the entropy of the approximate posterior.  Wake-sleep optimizes the approximate expectation of the joint density over samples from the approximate posterior / recognition net / inference net, while maximizing the approximate posterior over samples from the joint density. VAE maximizes both recognition and generation parameters through the lower bound via a clever reparameterization, also using an MCMC approximation for the expectation of the conditional. In addition to taking samples from the approximate posterior, NVIL uses learned baselines to reduce variance when estimating model parameters.

We restrict ourselves to the case where there is one latent layer and prior is factorial. In order to augment our inference from those available from the parameterized approximate posterior, we wish to achieve a better posterior by taking a set number of iterative steps in the variational parameters, $z$. That is, given the approximate posterior has the form:

\begin{align}
\tilde{q}(h|x; z) = \prod_i \tilde{q}(h_i|x; z),
\end{align}
we define the E-step loss function as

\begin{align}
\LL = \frac{1}{N} \sum_{h^n} \log p(x, h^n) - \log \tilde{q}(h^n),
\end{align}
such that we infer the variational parameters by applying iterative steps of gradient descent:

\begin{align}
\grad_z \LL &= \frac{1}{N} \grad_z \big(\sum_{h^n} \log p(x, h^n) - \log \tilde{q}(h^n)\big) \nonumber \\
z_t &= z_{t-1} + \gamma \grad_z \LL 
\end{align}
where $\gamma$ is the "inference rate".

Readers will probably notice immediately that the gradient in not tractable due to the stochastic variables used to calculate the expectation. However, we will show below that some straightforward to clever approximations can yield a \emph{deterministic} function w.r.t. the variational parameters, thus making the gradient descent quite easy.

It may be that the number of inference steps required to infer a good approximate posterior may be prohibitively high, and we have some flexibility in the initial parameters $z_0$. So as to speed up learning, and because there is a chance that this optimization may be non-convex, we initialize the variational parameters given by a parametric function $z_0 = q_{\PP}(h|x)$ defined by a feed forward network. If we optimize the auxiliary network to minimize the KL divergence between the output of the network and the approximate posterior found in our gradient descent procedure, we reach variational inference in the limit of no additional gradient steps.

\section{Continuous Latent Variables}

Let us assume that our approximate posterior and prior distributions are parameterized by multivariate normal distributions with diagonal covariance. As in VAE, the KL divergence $KL(\tilde{q}(h|x) || p(h))$ can be calculated exactly, but the conditional term $\qexp{p(x|h)}_{\tilde{q}}$ must be approximated by sampling from $\tilde{q}$. 

In order to pass the gradient of the approximate log conditional to the variational parameters, we can reparameterize our approximate posterior by:

\begin{align}
h = \mu + \epsilon \odot \sigma
\end{align}
where $(\mu, \sigma) = z$ are the mean and variance parameters for the posterior density and $\epsilon \sim \NN(0, 1)$. The gradients of the approximate lower bound w.r.t. the variational parameters $z$ can be calculated easily using back propagation.

\section{Training Procedure}
Much like traditional variational inference, our training procedure follows an EM algorithm.

\subsection{E Step: Approximately Inferring $p(h|x)$}
Our inference procedure is equivalent to 
\begin{align*}
    &\argmax_{q}  \sum_h \tilde{q}(h|x) \log p(x,h) + \HH(\tilde{q}) \\
    =& \argmax_{z} \sum_h \tilde{q}(h|x; z) \log p(x,h) + \HH(\tilde{q}).
\end{align*}

\subsection{M Step: Estimating the Parameters $\TT$ and $\PP$}

Since the approximate inference has been computed, it is rather straightforward
to compute the conditional term of the gradient of Eq.~\eqref{eq:approx_logp}:

\begin{align*}
    \nabla_{\TT} \qexp{\log p_{\TT}(x|h)}_{\tilde{q}} \approx \frac{1}{N} \sum_{h^n} \nabla_{\TT} \log p_{\TT}(x|h^n)
\end{align*}

where $h^n \sim \tilde{q}(h|x)$ are samples from the approximate posterior with the parameters $z^{\star}$ obtained from the E-step. In order to make our inference procedure more efficient, we also optimize the auxiliary parameters $\PP$ of the auxiliary network $q_{\PP}(h|x)$ by minimizing:

\begin{align}
    \label{eq:c_q}
    C_q(\PP) = KL(\tilde{q}(h|x)||q_{\PP}(h|x)).
\end{align}

\section{Binary Latent Variables}
Unfortunately, the parameterization available to us with continuous latent variables with multivariate normal distributions is not available to us with binary latent variables. In order to use gradient descent to back-propagate the gradients of the lower bound, we need to make a stronger approximation than the one used above. 

There has been some recent work into passing gradients through binary latent variables. Notably, we try two methods: one, we pass the centers of the Bernoulli distribution rather than sampling. That is, our loss becomes:

\begin{align}
	 \LL_e = -(\log p(x | \mu) + \qexp{\log p(h)}_{\tilde{q}} - \qexp{\log \tilde{q}}),
\end{align}
where $\log p(x | \mu)$ is the log-output of the generation network using the variational parameters $\mu = sigmoid(z)$. Note that the prior and entropy terms can be computed exactly without sampling.

The other option we explore here is to use the \emph{straight through} (ST) \cite{bengio2013estimating} estimator introduced in ... This amounts to using the MCMC approximation for the log conditional and approximating the gradient of w.r.t the variational parameters as:

\begin{align}
	\frac{\partial \LL_e}{\partial z} &=  -\frac{1}{N} \sum_n \frac{\partial}{\partial h^n} \log p(x|h^n) \nonumber \\
	&- \frac{\partial}{\partial z} \big( \qexp{\log p(h)}_{\tilde{q}} - \qexp{\log \tilde{q}} \big) 
\end{align}

\section{Related Work}
Our work combines many elements found in variational inference and MCMC methods. In spirit, it is closest to MCMC variational inference, yet it does not make use of an auxiliary network to perform the MCMC transitions, thus does not require extra parameters nor parameterization choice in inference outside of the normal inference network. In parameterization then it is very similar to VAE, wake-sleep, and NVIL, assuming a factorial prior.

Recent work on stochastic variational inference \cite{hoffman2013stochastic} also uses gradient descent to improve on the variational inference algorithm. However, their work is limited to the exponential family and do not make use of the MCMC approximation for the log conditional, nor a feed forward network to parameterize inference.

\section{Experiments}
We test our model on the standard binarized MNIST task on handwritten digits with a train, validation, and test split of 50k, 10k, and 10k samples. For the continuous latent variable case we used the same network structure as in \cite{kingma2013auto, salimans2014markov}, with $200$ continuous latent variables and a generation and recognition network with $500$ deterministic softplus units.
\section{Discussion}
todo

\bibliographystyle{abbrv}
\bibliography{ICLRbib}

\end{document}






